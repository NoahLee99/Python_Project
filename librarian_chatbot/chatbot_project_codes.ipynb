{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° í˜¸ì¶œ\n",
        "!pip install ipywidgets pdfplumber openai==0.28 konlpy\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML\n",
        "import warnings\n",
        "from google.colab import output, files\n",
        "import openai\n",
        "import pdfplumber\n",
        "from konlpy.tag import Okt\n",
        "import re\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "dsuDXZMGN8sz",
        "outputId": "649cde9c-4ded-4588-aff3-12299ebabda0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (7.7.1)\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.7-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (3.12.15)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.0.15)\n",
            "Collecting pdfminer.six==20250506 (from pdfplumber)\n",
            "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.3.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250506->pdfplumber) (3.4.3)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250506->pdfplumber) (43.0.3)\n",
            "Collecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading jpype1-1.6.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from konlpy) (5.4.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.11/dist-packages (from konlpy) (2.0.2)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.8.15)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2025.8.3)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.7)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.4.0->aiohttp->openai==0.28) (4.14.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (5.8.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.9.0.post0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.6)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.22.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.22)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (4.3.8)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.1->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (1.17.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.27.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.7)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.10.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfplumber-0.11.7-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jpype1-1.6.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (496 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m496.6/496.6 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, JPype1, jedi, konlpy, pdfminer.six, openai, pdfplumber\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.99.8\n",
            "    Uninstalling openai-1.99.8:\n",
            "      Successfully uninstalled openai-1.99.8\n",
            "Successfully installed JPype1-1.6.0 jedi-0.19.2 konlpy-0.6.0 openai-0.28.0 pdfminer.six-20250506 pdfplumber-0.11.7 pypdfium2-4.30.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ê²½ê³  ë©”ì‹œì§€ í•„í„°ë§\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Colab ìœ„ì ¯ ë§¤ë‹ˆì € í™œì„±í™” (UIê°€ ì œëŒ€ë¡œ í‘œì‹œë˜ë„ë¡)\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "# API í‚¤ ì„¤ì •\n",
        "openai.api_key = \"ë³¸ì¸ì´ ë°œê¸‰ ë°›ì€ key\""
      ],
      "metadata": {
        "id": "KN2Nn5XCU_tY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KoNLPy í•œêµ­ì–´ ìì—°ì–´ì²˜ë¦¬ íŒŒì´ì¬ íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬\n",
        "okt = Okt() # ê°ì²´ ì´ˆê¸°í™”\n",
        "\n",
        "# ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
        "korean_stopwords = [\n",
        "    'ì€', 'ëŠ”', 'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì—', 'ì—ì„œ', 'ì—ê²Œ', 'ì—ê²Œì„œ', 'ìœ¼ë¡œ', 'ë¡œ', 'ì™€', 'ê³¼',\n",
        "    'ë„', 'ë§Œ', 'ìš”', 'ë‹¤', 'ìŠµë‹ˆë‹¤', 'ã…‚ë‹ˆë‹¤', 'ìŠµë‹ˆë‹¤', 'ìˆë‹¤', 'í•©ë‹ˆë‹¤', 'ê²ƒ', 'ìˆ˜', 'ê°™ë‹¤', 'ìˆë‹¤',\n",
        "    'ì²˜ëŸ¼', 'ë“¯ì´', 'ìœ„í•´', 'í†µí•´', 'ë“±', 'ì´ë‹¤', 'ì•„ë‹ˆë‹¤', 'ë§í•˜ë‹¤', 'ì•Œë‹¤', 'ë˜ë‹¤', 'ì§€ë‹¤', 'ë³´ë‹¤',\n",
        "    'ë•Œ', 'ë¡œ', 'ì—', 'ì—ì„œ', 'í•˜ë‹¤', 'ë•Œë¬¸', 'ë¡œë¶€í„°', 'í•˜ëŠ”', 'ë ', 'ê·¸', 'ì €', 'ìˆ˜', 'ë˜', 'ì•ˆ',\n",
        "    'ê·¸ê²ƒ', 'ì´ê²ƒ', 'ì €ê²ƒ', 'í•˜ë‚˜', 'ë‘˜', 'ì…‹', 'ë„·', 'ë‹¤ì„¯', 'ì—¬ì„¯', 'ì¼ê³±', 'ì—¬ëŸ', 'ì•„í™‰', 'ì—´',\n",
        "    'ì €í¬', 'ìš°ë¦¬', 'ìˆëŠ”', 'ìˆì—ˆë‹¤', 'ì´ë ‡ë‹¤', 'ê·¸ë ‡ë‹¤', 'ì €ë ‡ë‹¤', 'ì•Šë‹¤', 'ì—†ë‹¤'\n",
        "]\n",
        "\n",
        "# ë¶ˆìš©ì–´ ì œê±° í•¨ìˆ˜ ì •ì˜\n",
        "def preprocess_text_only_stopwords_removal(input_text):\n",
        "    # input_textê°€ ë¬¸ìì—´ì´ ì•„ë‹ ê²½ìš° ë¬¸ìì—´ë¡œ ê°•ì œ ë³€í™˜\n",
        "    if not isinstance(input_text, str):\n",
        "        if isinstance(input_text, list):\n",
        "            input_text = ' '.join(input_text)\n",
        "        else:\n",
        "            input_text = str(input_text)\n",
        "\n",
        "    words = []\n",
        "    tagged_words = okt.pos(input_text, norm=True, stem=True)\n",
        "\n",
        "    for word, tag in tagged_words:\n",
        "        # ëª…ì‚¬(Noun), ë™ì‚¬(Verb), í˜•ìš©ì‚¬(Adjective)ë§Œ ì„ íƒ\n",
        "        if tag in ['Noun', 'Verb', 'Adjective']:\n",
        "            # ë¶ˆìš©ì–´ ì•„ë‹ˆê³  ë‘ ê¸€ì ì´ìƒì¼ ê²½ìš°\n",
        "            if word not in korean_stopwords and len(word) > 1:\n",
        "                words.append(word)\n",
        "\n",
        "    return ' '.join(words) # ì „ì²˜ë¦¬ëœ ë‹¨ì–´ë“¤ì„ ê³µë°±ìœ¼ë¡œ ì—°ê²°í•œ ë¬¸ìì—´ ë°˜í™˜\n",
        "\n",
        "# í‚¤ì›Œë“œ ì¶”ì¶œ í•¨ìˆ˜ ì •ì˜ (Term Frequency ê³„ì‚°ìš©)\n",
        "def extract_keywords_with_tf(input_text_string):\n",
        "    processed_words_string = preprocess_text_only_stopwords_removal(input_text_string)\n",
        "    return Counter(processed_words_string.split())"
      ],
      "metadata": {
        "id": "uAIGTWDiVXVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PDF ì—…ë¡œë“œ ë° ê° íŒŒì¼ë³„ í…ìŠ¤íŠ¸ ì¶”ì¶œ & ì „ì²˜ë¦¬ ì‹¤í–‰\n",
        "print(\"ì„œí‰ PDF íŒŒì¼ë“¤ì„ ëª¨ë‘ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "if not uploaded:\n",
        "    print(\"ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
        "    raise SystemExit(\"No files uploaded.\")\n",
        "\n",
        "# ì „ì—­ ë³€ìˆ˜ ì„ ì–¸ ë° ì´ˆê¸°í™” (ëª¨ë“  í•¨ìˆ˜ì—ì„œ ì ‘ê·¼í•  ìˆ˜ ìˆë„ë¡ globalë¡œ ì„ ì–¸)\n",
        "global processed_document_chunks\n",
        "global document_titles\n",
        "\n",
        "processed_document_chunks = []\n",
        "document_titles = []\n",
        "\n",
        "# ì—…ë¡œë“œëœ ëª¨ë“  íŒŒì¼ ì´ë¦„ì„ ìˆœíšŒ\n",
        "for pdf_file_name in uploaded.keys():\n",
        "    print(f\"--- Processing file: {pdf_file_name} ---\")\n",
        "    current_pdf_raw_text = \"\"\n",
        "    try:\n",
        "        with pdfplumber.open(pdf_file_name) as pdf:\n",
        "            for page in pdf.pages:\n",
        "                page_text = page.extract_text()\n",
        "                if page_text:\n",
        "                    current_pdf_raw_text += page_text + \"\\n\"\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while extracting text from '{pdf_file_name}': {e}\")\n",
        "        continue\n",
        "\n",
        "    preprocessed_doc_text = preprocess_text_only_stopwords_removal(current_pdf_raw_text)\n",
        "\n",
        "    processed_document_chunks.append(preprocessed_doc_text)\n",
        "    document_titles.append(pdf_file_name)\n",
        "\n",
        "    print(f\"'{pdf_file_name}' ì „ì²˜ë¦¬ í›„ ê¸€ì ìˆ˜: {len(preprocessed_doc_text)}\")\n",
        "\n",
        "print(\"\\nëª¨ë“  ì„œí‰ PDF íŒŒì¼ ì „ì²˜ë¦¬ ì™„ë£Œ!\")\n",
        "\n",
        "# ì‹œìŠ¤í…œì´ ì¸ì‹í•˜ëŠ” ì±… ì œëª© í™•ì¸ (ë””ë²„ê¹…ìš©)\n",
        "print(\"\\n\\nì‹œìŠ¤í…œì´ ì¸ì‹í•˜ëŠ” ì±… ì œëª© ëª©ë¡\")\n",
        "for i, title in enumerate(document_titles):\n",
        "    clean_title = title.replace('.pdf', '').strip().lower()\n",
        "    print(f\"ì›ë³¸ íŒŒì¼ëª…: '{title}' -> ì‹œìŠ¤í…œ ì¸ì‹ ì œëª©: '{clean_title}'\")"
      ],
      "metadata": {
        "id": "3o8o3TozVtyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì´ì „ ëŒ€í™” ê¸°ë¡(ë¡œê·¸) ì €ì¥ ë³€ìˆ˜ ì´ˆê¸°í™”\n",
        "initial_system_message_content = (\n",
        "    \"ë‹¹ì‹ ì€ ì±… ì†Œê°œ ë¬¸ì„œë¥¼ ì´í•´í•˜ê³  ì‘ë‹µí•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤. \"\n",
        "    f\"ë‹¤ìŒ ì±…ë“¤ì— ëŒ€í•´ ì§ˆë¬¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤: {', '.join([title.replace('.pdf', '') for title in document_titles])}. \"\n",
        "    \"ì§ˆë¬¸ ì‹œì—ëŠ” ì–´ë–¤ ì±…ì— ëŒ€í•œ ì§ˆë¬¸ì¸ì§€ ëª…ì‹œí•´ ì£¼ì‹œë©´ ë” ì •í™•í•œ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\"\n",
        "    \"ì˜ˆì‹œ ì§ˆë¬¸: 'ì‚¬ë‘ì˜ ê¸°ìˆ ì„ ìš”ì•½í•´ì¤˜.', 'ì‚¬ë‘ì˜ ê¸°ìˆ ì˜ ë¹„í†µì œ ìƒ‰ì¸ì–´ë¥¼ ë§Œë“¤ì–´ì¤˜', 'ëª¨ë“  ì±…ë“¤ì˜ í‚¤ì›Œë“œë¥¼ ì•Œë ¤ì¤˜'\"\n",
        ")\n",
        "\n",
        "# ëŒ€í™” ê¸°ë¡ ì €ì¥ ë¦¬ìŠ¤íŠ¸\n",
        "conversation_history = [\n",
        "    {\"role\": \"system\", \"content\": initial_system_message_content}\n",
        "]"
      ],
      "metadata": {
        "id": "ClEFO2nRV0Ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ChatGPT API í˜¸ì¶œ í•¨ìˆ˜ ì •ì˜ (ëŒ€í™” ê¸°ë¡ ë°˜ì˜ ver)\n",
        "def ask_chatgpt_with_history(user_question):\n",
        "    global conversation_history\n",
        "    global processed_document_chunks\n",
        "    global document_titles\n",
        "\n",
        "    selected_doc_text_for_prompt = \"\"\n",
        "    selected_doc_title_for_prompt = \"ì—¬ëŸ¬ ë¬¸ì„œ ìš”ì•½\"\n",
        "\n",
        "    found_relevant_doc = False\n",
        "    for i, title in enumerate(document_titles):\n",
        "        clean_title = title.replace('.pdf', '').strip().lower()\n",
        "        if clean_title in user_question.lower():\n",
        "            selected_doc_text_for_prompt = processed_document_chunks[i]\n",
        "            selected_doc_title_for_prompt = title\n",
        "            found_relevant_doc = True\n",
        "            break\n",
        "\n",
        "    if not found_relevant_doc:\n",
        "        combined_docs_preview = []\n",
        "        for i, doc_text in enumerate(processed_document_chunks):\n",
        "            combined_docs_preview.append(f\"[{document_titles[i].replace('.pdf', '')}]: {doc_text[:300]}...\")\n",
        "\n",
        "        selected_doc_text_for_prompt = \"\\n\\n\".join(combined_docs_preview)\n",
        "\n",
        "    effective_document_for_prompt = selected_doc_text_for_prompt[:3000]\n",
        "\n",
        "    new_system_message = {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": (\n",
        "            f\"ë‹¹ì‹ ì€ ì±… ì†Œê°œ ë¬¸ì„œë¥¼ ì´í•´í•˜ê³  ì‘ë‹µí•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤. ë‹¤ìŒ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”:\\n\\n\"\n",
        "            f\"ì°¸ê³  ë¬¸ì„œ ë‚´ìš© ({selected_doc_title_for_prompt.replace('.pdf', '')})\\n\"\n",
        "            f\"{effective_document_for_prompt}\\n\"\n",
        "            f\"--------------------------------------------------\\n\"\n",
        "            f\"ë§Œì•½ ìœ„ ë¬¸ì„œ ë‚´ìš©ì— í•´ë‹¹ ì •ë³´ê°€ ëª…í™•íˆ ì—†ìœ¼ë©´, 'ë¬¸ì„œì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'ë¼ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.\"\n",
        "        )\n",
        "    }\n",
        "\n",
        "    current_dialog_turns_only = conversation_history[1:]\n",
        "\n",
        "    # ìµœëŒ€ ëŒ€í™” ê¸°ë¡ ë°˜ì˜ ìˆ˜ 5ê°œë¡œ ì„¤ì •\n",
        "    MAX_CONVERSATION_TURNS = 5\n",
        "    if len(current_dialog_turns_only) > (MAX_CONVERSATION_TURNS * 2):\n",
        "        current_dialog_turns_only = current_dialog_turns_only[-(MAX_CONVERSATION_TURNS * 2):]\n",
        "\n",
        "    messages_to_model = [new_system_message] + current_dialog_turns_only\n",
        "\n",
        "    try:\n",
        "        messages_to_model.append({\"role\": \"user\", \"content\": user_question})\n",
        "\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=messages_to_model,\n",
        "            temperature=0.2, # ì‚¬ì‹¤ ê¸°ë°˜ ë‹µë³€ì„ ìœ„í•´ temperature ë§¤ê°œë³€ìˆ˜ ê°’ì„ 0.2ë¡œ ì„¤ì •\n",
        "            max_tokens=500\n",
        "        )\n",
        "        if not response.choices or not response.choices[0].message[\"content\"]:\n",
        "            raise ValueError(\"The model responded with an empty message.\")\n",
        "\n",
        "        chatbot_response_content = response.choices[0].message[\"content\"]\n",
        "\n",
        "        conversation_history.append({\"role\": \"user\", \"content\": user_question})\n",
        "        conversation_history.append({\"role\": \"assistant\", \"content\": chatbot_response_content})\n",
        "\n",
        "        return chatbot_response_content\n",
        "\n",
        "    except Exception as e:\n",
        "        if conversation_history and conversation_history[-1][\"role\"] == \"user\":\n",
        "            conversation_history.pop()\n",
        "        return f\"ì£„ì†¡í•©ë‹ˆë‹¤, ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì— ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\""
      ],
      "metadata": {
        "id": "BqLNyLg3V6Ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ìœ„ì ¯ êµ¬ì„±\n",
        "chat_display = widgets.HTML(value=\"<b>ğŸ“„ ì±…ë´‡ì—ê²Œ ì§ˆë¬¸í•´ ë³´ì„¸ìš”!</b><hr>\")\n",
        "chat_log = \"\"\n",
        "\n",
        "input_box = widgets.Textarea(\n",
        "    placeholder='ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì‚¬ë‘ì˜ ê¸°ìˆ ì˜ ì¤„ê±°ë¦¬ëŠ”? / ì‚¬ë‘ì˜ ê¸°ìˆ ì˜ ë¹„í†µì œ ìƒ‰ì¸ì–´ ë§Œë“¤ì–´ì¤˜ / ëª¨ë“  ì±… í‚¤ì›Œë“œ ì•Œë ¤ì¤˜)',\n",
        "    layout=widgets.Layout(width='100%', height='80px')\n",
        ")\n",
        "\n",
        "send_button = widgets.Button(description=\"ğŸ’¬ ì§ˆë¬¸í•˜ê¸°\", button_style='info')\n",
        "\n",
        "# ë²„íŠ¼ ë™ì‘ ì •ì˜\n",
        "def on_send_clicked(b):\n",
        "    global chat_log\n",
        "    user_input = input_box.value.strip()\n",
        "    if not user_input:\n",
        "        return\n",
        "    input_box.value = \"\"\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    chat_log += f\"<div style='margin-bottom:10px'><b>ğŸ™‹ ì‚¬ìš©ì:</b> {user_input}</div>\"\n",
        "\n",
        "    current_chat_display_value = chat_log + \"<div><i>ğŸ¤– ChatGPT ì…ë ¥ ì¤‘...</i></div>\"\n",
        "    chat_display.value = current_chat_display_value\n",
        "    display(chat_display, input_box, send_button)\n",
        "\n",
        "    answer = \"\"\n",
        "    try:\n",
        "        user_input_lower = user_input.lower()\n",
        "        user_input_no_spaces = user_input_lower.replace(\" \", \"\") # ì‚¬ìš©ì ì…ë ¥ì—ì„œ ëª¨ë“  ê³µë°± ì œê±°\n",
        "\n",
        "        # KORMARC 520 íƒœê·¸ ê¸°ëŠ¥\n",
        "        kormarc_520_trigger_terms = [\"520 íƒœê·¸\", \"520 tag\", \"ìš”ì•½ íƒœê·¸\", \"ìš”ì•½ ì£¼ê¸°\", \"520 marc\", \"520 MARC\", \"520 ë§ˆí¬\"]\n",
        "        if any(term in user_input_lower for term in kormarc_520_trigger_terms):\n",
        "            selected_doc_text_for_summary = \"\"\n",
        "            selected_doc_title_for_summary = \"ëª¨ë“  ë¬¸ì„œ ìš”ì•½\"\n",
        "\n",
        "            found_specific_book_for_summary = False\n",
        "            for i, title in enumerate(document_titles):\n",
        "                # ë¬¸ì„œ ì œëª©ë„ ë¹„êµë¥¼ ìœ„í•´ ê³µë°± ì œê±°\n",
        "                clean_title_no_spaces = title.replace('.pdf', '').strip().lower().replace(\" \", \"\")\n",
        "                # ê³µë°± ì œê±°ëœ ì‚¬ìš©ì ì…ë ¥ê³¼ ê³µë°± ì œê±°ëœ ë¬¸ì„œ ì œëª© ë¹„êµ\n",
        "                if clean_title_no_spaces in user_input_no_spaces:\n",
        "                    selected_doc_text_for_summary = processed_document_chunks[i]\n",
        "                    selected_doc_title_for_summary = title\n",
        "                    found_specific_book_for_summary = True\n",
        "                    break\n",
        "\n",
        "            if not found_specific_book_for_summary:\n",
        "                combined_docs_preview_summary = []\n",
        "                for i, doc_text in enumerate(processed_document_chunks):\n",
        "                    combined_docs_preview_summary.append(f\"[{document_titles[i].replace('.pdf', '')}]: {doc_text[:300]}...\")\n",
        "                selected_doc_text_for_summary = \"\\n\\n\".join(combined_docs_preview_summary)\n",
        "\n",
        "            kormarc_520_prompt = (\n",
        "                f\"ë‹¤ìŒ ì±… ì†Œê°œ ë¬¸ì„œì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ KORMARC 520 íƒœê·¸(ìš”ì•½)ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”. \"\n",
        "                f\"ë°˜ë“œì‹œ '520 ## $a ' í˜•ì‹ìœ¼ë¡œ ì‹œì‘í•˜ê³ , ë’¤ì— ìš”ì•½ í…ìŠ¤íŠ¸ë¥¼ ë¶™ì—¬ì£¼ì„¸ìš”. \"\n",
        "                f\"ìš”ì•½ í…ìŠ¤íŠ¸ëŠ” ê°„ê²°í•˜ê³  í•µì‹¬ì ì¸ ë‚´ìš©ìœ¼ë¡œ 100ì ì´ë‚´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”. \"\n",
        "                f\"ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ ë¬¸ì¥ ì—†ì´ KORMARC íƒœê·¸ í˜•ì‹ë§Œ ì¶œë ¥í•˜ì„¸ìš”.\"\n",
        "                f\"ë¬¸ì„œ ë‚´ìš©: {selected_doc_text_for_summary[:3000]}\"\n",
        "            )\n",
        "\n",
        "            generated_kormarc_520 = ask_chatgpt_with_history(kormarc_520_prompt)\n",
        "\n",
        "            answer = f\"ğŸ¤– ì±…ë´‡ ì œì•ˆ KORMARC 520 íƒœê·¸ ({selected_doc_title_for_summary.replace('.pdf', '')} ì°¸ê³ ):\\n\"\n",
        "            answer += f\"```\\n{generated_kormarc_520}\\n```\\n\"\n",
        "\n",
        "        # KORMARC 653 íƒœê·¸ ìƒì„± ë° ìµœë¹ˆ í‚¤ì›Œë“œ ì œì‹œ ê¸°ëŠ¥\n",
        "        kormarc_653_trigger_terms = [\"ë¹„í†µì œ ìƒ‰ì¸ì–´\", \"kormarc 653\", \"653 tag\", \"653 marc\", \"í•µì‹¬ ë‹¨ì–´\", \"í•µì‹¬ í‚¤ì›Œë“œ\", \"í•µì‹¬ì–´\", \"ìƒ‰ì¸ì–´\", \"653 íƒœê·¸\", \"653 ë§ˆí¬\"]\n",
        "        if any(term in user_input_lower for term in kormarc_653_trigger_terms):\n",
        "            selected_doc_text_for_kormarc = \"\"\n",
        "            selected_doc_title_for_kormarc = \"ëª¨ë“  ë¬¸ì„œ ìš”ì•½\"\n",
        "            found_specific_book_for_kormarc = False\n",
        "\n",
        "            # ê° ë¬¸ì„œ ì œëª©ì„ ìˆœíšŒí•˜ë©° ì‚¬ìš©ì ì…ë ¥ê³¼ ë§¤ì¹­ ì‹œë„\n",
        "            for i, title in enumerate(document_titles):\n",
        "                clean_title_for_comparison = title.replace('.pdf', '').strip().lower()\n",
        "                if clean_title_for_comparison in user_input_lower:\n",
        "                    selected_doc_text_for_kormarc = processed_document_chunks[i]\n",
        "                    selected_doc_title_for_kormarc = title\n",
        "                    found_specific_book_for_kormarc = True\n",
        "                    break\n",
        "\n",
        "            if not found_specific_book_for_kormarc:\n",
        "                combined_docs_preview_kormarc = []\n",
        "                for i, doc_text in enumerate(processed_document_chunks):\n",
        "                    combined_docs_preview_kormarc.append(f\"[{document_titles[i].replace('.pdf', '')}]: {doc_text[:300]}...\")\n",
        "                selected_doc_text_for_kormarc = \"\\n\\n\".join(combined_docs_preview_kormarc)\n",
        "\n",
        "            kormarc_prompt = (\n",
        "                f\"ë‹¤ìŒ ì±… ì†Œê°œ ë¬¸ì„œì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ KORMARC 653 íƒœê·¸(ë¹„í†µì œ ìƒ‰ì¸ì–´)ì— í•´ë‹¹í•˜ëŠ” í•µì‹¬ í‚¤ì›Œë“œ 5ê°œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”. \"\n",
        "                f\"ì˜ˆì‹œ: '$aë…ì„œ ì‹¬ë¦¬ $aê´€ê³„ í˜•ì„± $aê°ì„± ì§€ëŠ¥ $aë…ì„œ í´ëŸ½ $aë„ì„œê´€ ì´ìš©' ê³¼ ê°™ì´ KORMARC í˜•ì‹ì— ë§ì¶° ì¶œë ¥í•´ì£¼ì„¸ìš”. \"\n",
        "                f\"ì¶”ê°€ ì„¤ëª… ì—†ì´ ìƒ‰ì¸ì–´ë§Œ ì¶œë ¥í•˜ì„¸ìš”.\"\n",
        "                f\"ë¬¸ì„œ ë‚´ìš©: {selected_doc_text_for_kormarc[:3000]}\\n\"\n",
        "                f\"ë°˜ë“œì‹œ '653 ## $a ' í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.\"\n",
        "            )\n",
        "\n",
        "            generated_kormarc_terms = ask_chatgpt_with_history(kormarc_prompt)\n",
        "\n",
        "            if found_specific_book_for_kormarc:\n",
        "                keywords_for_tf = extract_keywords_with_tf(selected_doc_text_for_kormarc)\n",
        "                current_book_title = selected_doc_title_for_kormarc.replace('.pdf', '')\n",
        "            else:\n",
        "                keywords_for_tf = extract_keywords_with_tf(\" \".join(processed_document_chunks))\n",
        "                current_book_title = \"ëª¨ë“  ë¬¸ì„œ\"\n",
        "\n",
        "            top_3_keywords = keywords_for_tf.most_common(3)\n",
        "\n",
        "            answer = f\"ğŸ¤– ì±…ë´‡ ì œì•ˆ ë¹„í†µì œ ìƒ‰ì¸ì–´ ({current_book_title} ì°¸ê³ ):\\n\"\n",
        "            answer += f\"```\\n{generated_kormarc_terms}\\n```\\n\\n\"\n",
        "            answer += \"<br>ğŸ’¡ ì°¸ê³ : ë¬¸ì„œì—ì„œ ê°€ì¥ ë§ì´ ì¶œí˜„í•œ í‚¤ì›Œë“œ (TF ë¶„ì„ ê²°ê³¼)\\n\"\n",
        "            if top_3_keywords:\n",
        "                for keyword, count in top_3_keywords:\n",
        "                    answer += f\"<br>âš ï¸ {keyword} (ë“±ì¥ íšŸìˆ˜: {count}íšŒ)<br>\"\n",
        "            else:\n",
        "                answer += \"í‚¤ì›Œë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.<br>\"\n",
        "\n",
        "        # ì¼ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ ë¡œì§\n",
        "        elif \"í‚¤ì›Œë“œ\" in user_input_lower or \"í•µì‹¬ì–´\" in user_input_lower:\n",
        "            relevant_doc_text_for_keywords = \"\"\n",
        "            current_book_title_for_keywords = \"ëª¨ë“  ë¬¸ì„œ\"\n",
        "            found_specific_book_for_keywords = False\n",
        "\n",
        "            # ê° ë¬¸ì„œ ì œëª©ì„ ìˆœíšŒí•˜ë©° ì‚¬ìš©ì ì…ë ¥ê³¼ ë§¤ì¹­ ì‹œë„ (ë™ì¼í•œ ë¡œì§)\n",
        "            for i, title in enumerate(document_titles):\n",
        "                clean_title_for_comparison = title.replace('.pdf', '').strip().lower()\n",
        "                if clean_title_for_comparison in user_input_lower:\n",
        "                    relevant_doc_text_for_keywords = processed_document_chunks[i]\n",
        "                    current_book_title_for_keywords = title.replace('.pdf', '')\n",
        "                    found_specific_book_for_keywords = True\n",
        "                    break\n",
        "\n",
        "            if not found_specific_book_for_keywords:\n",
        "                combined_all_text_for_keywords = \" \".join(processed_document_chunks)\n",
        "                keywords_counter = extract_keywords_with_tf(combined_all_text_for_keywords)\n",
        "            else:\n",
        "                keywords_counter = extract_keywords_with_tf(relevant_doc_text_for_keywords)\n",
        "\n",
        "            top_keywords_list = [word for word, count in keywords_counter.most_common(20)]\n",
        "            answer = f\"({current_book_title_for_keywords} ì°¸ê³ ) ì¶”ì¶œëœ ì£¼ìš” í‚¤ì›Œë“œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤: {', '.join(top_keywords_list)}\"\n",
        "\n",
        "        else:\n",
        "            answer = ask_chatgpt_with_history(user_input)\n",
        "\n",
        "    except Exception as e:\n",
        "        answer = f\"ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ì— ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\"\n",
        "\n",
        "    chat_log += f\"<div style='margin-bottom:20px'><b>ğŸ¤– ChatGPT:</b> {answer}</div>\"\n",
        "    chat_display.value = chat_log\n",
        "\n",
        "# ë²„íŠ¼ í´ë¦­ ì´ë²¤íŠ¸ ì—°ê²°\n",
        "send_button.on_click(on_send_clicked)\n",
        "\n",
        "# ì±—ë´‡ UI ì¶œë ¥\n",
        "display(chat_display)\n",
        "display(input_box, send_button)"
      ],
      "metadata": {
        "id": "cCjiTUz0V6Xq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}